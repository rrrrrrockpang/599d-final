<!DOCTYPE html>
<html lang="en">
<head>
  <title>A 20-Year Analysis of the Intersection of HCI and AI Research</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css">
  <link rel="stylesheet" href="style.css">
  <!-- <link rel="stylesheet" href="main.css"> -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
  <script src="https://code.jquery.com/color/jquery.color-2.2.0.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js"></script>


  <!-- Load d3.js -->
  <script src="./d3.v5.min.js" charset="utf-8"></script>
  <script src="scripts.js"></script>

  <script src="https://cdn.plot.ly/plotly-2.16.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/4.6.2/js/bootstrap.min.js"></script>
</head>

<body>

<div class="col-lg-6 offset-lg-3">
  <h1>A 20-Year Analysis of the Intersection of HCI and AI Research</h1>
  <!-- <p><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-info-circle" viewBox="0 0 16 16">
    <path d="M8 15A7 7 0 1 1 8 1a7 7 0 0 1 0 14zm0 1A8 8 0 1 0 8 0a8 8 0 0 0 0 16z"/>
    <path d="m8.93 6.588-2.29.287-.082.38.45.083c.294.07.352.176.288.469l-.738 3.468c-.194.897.105 1.319.808 1.319.545 0 1.178-.252 1.465-.598l.088-.416c-.2.176-.492.246-.686.246-.275 0-.375-.193-.304-.533L8.93 6.588zM9 4.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0z"/>
  </svg> This article contains <b>interactive figures</b>. Hover over markers in figures labelled as <span class="int-img-label">Interactive Figures</span> to reveal more information.</p> -->

  <hr>
  <div class="row metadata">
    <div class="col author"><b>Kevin Feng</b><br> Human Centered Design & Engineering <br> Unversity of Washington <br> Seattle, WA, USA <br> kjfeng@uw.edu</div>
    <div class="col author"><b>Tony Li</b> <br> Human Centered Design & Engineering <br> Unversity of Washington <br> Seattle, WA, USA <br> tonywli@uw.edu</div>
    <div class="col author"><b>Rock Pang</b><br> Computer Science & Engineering <br> Unversity of Washington <br> Seattle, WA, USA <br> ypang2@cs.washington.edu</div>
    <div class="col author"><b>Yiwei Yang</b> <br> The Information School <br> Unversity of Washington <br> Seattle, WA, USA <br> yanyiwei@uw.edu</div>
  </div>
  <br>
  <p class="metadata">The authors above contributed equally to this work. </p>
  <!-- <p class="metadata">DOI: <a href="https://doi.org/10.1145/3334480.3382994">https://doi.org/10.1145/3334480.3382994</a>. <br> CHI '20: <a href="https://dl.acm.org/doi/proceedings/10.1145/3334480">CHI Conference on Human Factors in Computing Systems Extended Abstracts</a>, Honolulu, USA, April 2020</p>

  <p class="metadata">CCS Concepts: Human-centered computing∼Human computer interaction (HCI)∼Interactive systems and tools∼User interface programming
  </p> 

  <p class="metadata">Keywords: Programming, Authoring Environments, Creative Coding, Design Tools</p>

  <p class="metadata">ACM Reference Format:
    Cameron Burgess*, Dan Lockton, Maayan Albert* and Daniel Cardoso Llach. 2020. Stamper: An Artboard-Oriented Creative Coding Environment. In Proceedings of CHI '20: CHI Conference on Human Factors in Computing Systems (CHI'20 Extended Abstracts), April 25-30, 2020, Honolulu, HI, USA. ACM, New York, NY, USA, <a href="https://doi.org/10.1145/3334480.3382994">https://doi.org/10.1145/3334480.3382994</a></p> -->

    <hr>

  </div>

  <div class="row main-body">
    <div class="col-lg-2 offset-lg-1 tc">
      <h5>Contents</h5> 
      <a href="#intro">Introduction</a><br>
      <a href="#related-work">Related Work</a><br>
      <a href="#method">Methodology</a><br>
      <a href="#findings">Findings</a><br>
      <a href="#discussion">Discussion</a><br>
      <a href="#conclusion">Conclusion</a><br>
      <a href="#materials">Materials</a>

    </div>
    <div class="col-lg-6 main-body">
      <!-- intro section -->
      <section style="padding-top: 1rem; margin-top: 0" id="intro">
        <p>In a 2009 article published in <i>AI Magazine</i><span class="citation" id="1"></span>, Jonathan Grudin describes Human-Computer Interaction (HCI) and Artificial Intelligence (AI) as "two fields divided by a common focus." He claims that HCI focuses on new technologies that promises widespread availability, while AI research also focuses on new technologies but with very limited availability due to expensive computing resources. </p>

        <p>Today, the landscape looks dramatically different. The fruits of AI research has been made available to more members of the public thanks to advancements in hardware and software infrastructures for managing machine learning pipelines as well as distribution of AI resources via cloud computing. As AI interfaces more with people, HCI researchers are increasingly interested in leveraging new technological capabilities enabled by AI to develop novel interactive systems and studying the impact of AI on human behaviour. It seems inevitable, then, that the two fields overlap and converge (and will continue to do so) in interesting ways.</p>

        <p>In this work, we explore the intersection of HCI and AI by examining the academic publications in each area. We embody the two fields by their flagship conferences: the ACM Conference CHI Conference on Human Factors in Computing Systems (CHI) for HCI, and the Conference on Neural Information Processing Systems (NeurIPS) for AI. Using works published at these two conferences for the past 20 years alongside modern NLP techiques, we aim to surface trends in the HCI-AI overlap and use those trends to unearth potential future research directions within this ever-growing intersection. </p>

      </section>

      <section id="related-work">
        <h3>Related Work</h3>
        <h4>Historical Relationships Between HCI and AI</h4>
        <p>The rise in popularity of "usable AI"- and "human-AI interaction"-style conference events and workshops in recent years is strong convergence between HCI and AI. The convergence is mutual. For the 2nd year in a row, NeurIPS is hosting the Human-Centered AI workshop to bring together members of the NeurIPS and HCI communities to "explore research questions that stem from the increasingly wide-spread usage of machine learning algorithms across all areas of society" <span class="citation" id="2"></span>. CHI workshops have also been engaging with AI topics and practitoners, such as the 2019 workshop on "bridging the gap between AI and HCI (CHI 2019)" <span class="citation" id="3"></span> as well as one on "trust and reliance in humam-AI teams (CHI 2022)"  <span class="citation" id="4"></span>. However, even before these events became popular, researchers have long been tracking the history of AI and HCI to find intersections. Grudin <span class="citation" id="1"></span> mapped out AI "summers" and "winters" starting in the 1950s and declared that HCI's greatest periods of development (most notably in the early 1980s when influential HCI labs formed at PARC, IBM, Bell Labs, and UCSD, among other places) corresponded with AI winters, when momentum behind AI research dwindled and so did funding. He posited that this was due to the two fields competing for common resources. However, we do not see strong evidence for the blistering pace of AI research today to take a toll on the growth of HCI; in fact, it's the opposite—HCI is enriched by new AI capabilities and limitations. We verify this observation through our analysis of HCI and AI publications.</p>

        <figure>
          <img src="./grudin-ai.png" alt="">
          <figcaption>Figure 1: Grudin's depiction of trends in AI research from 1950 to mid-2000s, from <span class="citation" id="1"></span>.</figcaption>
        </figure>

        <h4>Techniques for Analyzing Academic Papers</h4>
        <p>Researchers have previously attempted to identify research trends through historical analysis of conference publications. Liu et al. <span class="citation" id="5"></span> mapped 20 years of CHI publications from 1994 to 2013 via hierarchical cluster analysis, strategic visualizations, and network analysis and concluded that themes within HCI have become more cohesive, while the number of themes have simultaneously increased. They reasoned that external factors, such as the introduction of new technology, stimulates the development of new themes. They used the iPhone and Facebook as examples of new technology, so one can easily see how modern AI beakthroughs can fit the mould for an effective catalyst of new HCI work. In a 2018 blog post <span class="citation" id="6"></span>, the Microsoft Academic team presented a historical trend analytics of NeurIPS from 1996 to 2017 using the Microsoft Academic Graph. The post presented insights such as paper output over time, incoming and outgoing citations, top authors, and top institutions, but the analysis was constrained by metadata available in the graph. </p>

        <p>Advancements in NLP techniques bring a new dimension to this style of analysis. Google introduced BERT <span class="citation" id="7"></span> in 2018 as a new pre-trained language representation model to be easily fine-tuned for a wide range of tasks. SciBERT <span class="citation" id="8"></span> was released by the Allen Institute for AI in 2019 as a BERT model fine-tuned on a large multi-domain corpus of scientific publications. SciBERT was shown to outperform BERT-Base on a variety of tasks datasets in scientific domains and displays potential in creating powerful embeddings to signal document-level relatedness. Indeed, a follow-up work introduces SPECTER <span class="citation" id="9"></span>, a citation-based method to generate unsupervised, document-level embeddings based on a pretrained transformer model (such as SciBERT). SPECTER embeddings for papers on Semantic Scholar are available through the <a href="https://api.semanticscholar.org/api-docs/graph">Semantic Scholar Academic Graph API</a>. Unsupervised embeddings have been shown to capture complex in scientific domains, such as materials science, where Tshitoyan et al. found that they can learn representations of underlying structures of the periodic table and structure–property relationships in materials <span class="citation" id="10"></span>. Additionally, Tshitoyan et al. demonstrated that the embeddings can also be used to recommend materials for real-world applications ahead their discovery. Although some findings are specific to material science, many can be generalized to knowledge extraction approaches for scientific domains beyond material science. </p>

        <p>In our work, we leverage insights from previous work to conduct cross-disciplinary analysis of academic work to reveal new interdisciplinary research directions. Specifically, we use embeddings computed with SciBERT to identify relationships between papers published in CHI and NeurIPS and perform additional analysis to identify common trends and predict new ones.</p>

      </section>

      <section id="method">
        <h3>Methodology</h3>
        <p>We sourced our papers from <a href="https://dblp.org/">DBLP</a>, a bibliography website for computer science literature. We chose DBLP over DOI, despite DOI being more prevalent among academic citation networks, due to its ability to search papers by venue. We scraped CHI and NeurIPS papers from DBLP published between 2001 and 2021, including only conference proceedings (as opposed to workshop papers) to keep our dataset to a manageable size for analysis on a GPU-constrained cloud environment. While we only scraped paper titles, we then used the Semantic Scholar (S2) API to query papers using our titles to obtaining richer information about each paper, including the abstract and SPECTER embeddings. </p>
    
        <p>Once we had our dataset, we decided to compute our own embeddings as the SPECTER embeddings were not available for all papers in our dataset; 72.3% of papers across both conferences had them. To do so, we fed our paper titles into SciBERT to obtain a series of embeddings. We the computed an embedding similarity matrix with all combinations of papers via their respective conferences and years. We used cosine similarity as our similarity measurement. We then identify the top <i>n</i> most similar pairs as a filter to preserve literature that may lie close to or in the intersection of the two conferences. We then separate the filtered papers based in their conferences, obtaining a set of CHI papers that are similar to NeurIPS papers (as judged by their embeddings) and vice versa. We then perform k-means clustering within the pools of filtered papers in their respective conferences to look for topical similarities <i>within</i> each conference. With clusters of <i>k</i> papers from each of CHI and NeurIPS, we took the abstracts from those clusters and fed each abstract cluster into GPT-3 (text-davinci-003, temperature = 0.2) to obtain a keyphrase that summarizes the cluster, which we call the cluster's "topic". We then leverage our collection of AI-adjacent HCI topics and HCI-adjacent AI topics to propose future research directions at the intersection of AI and HCI. </p>
      </section>
    
      <figure>
        <img src="./process.png" alt="">
        <figcaption>Figure 2: A visual diagram of our process flow.</figcaption>
      </figure>
    
      <section id="findings">
        <h3>Findings</h3>
        <p>We analyzed a total of 14,000 papers from CHI and NeurIPS published between 2001 and 2021. We set <i>n = 100</i> and <i>k = 4</i> to obtain clusters of reasonable quality after some experimentation. To provide an overview of our dataset, we plotted the number of publications in each conference against the year. As per <a href="#overviewBarChart">Figure 3</a>, the size of CHI grew consistently over the years whereas NeurIPS grew steadily until about 2016, from which it started experiencing much more rapid growth. </p>
        <div id="overviewBarChart"></div>
        <figcaption>Figure 3: An overview of our dataset, by publication year.</figcaption>
        <!-- <div id="heatmapTitles"></div> -->
        <p>Upon computing embeddings, we plotted a heatmap of cosine similarity scores of abstracts from papers in our dataset, with a conference on each axis <a href="#heatmapAbstracts">Figure 4</a>. We notice that the gradation of color lies primarily along the y-axis. This means that the change in similarity over a longer-term span of CHI publications for a particular year of NeurIPS is typically greater than the reverse. The asymmetry indicates that NeurIPS has a greater influence on CHI than vice versa. That said, the slight gradation along the x-axis in more recent years of CHI indicates that HCI may exert an increasingly non-neglegible influence in AI. The accumulation of high similarity scores in the top right corner of the chart confirms the convergence of AI and HCI as indicated by previous, more qualitative analyses. </p>

        <div id="heatmapAbstracts"></div>
        <figcaption>Figure 4: Heatmap of cosine similarity among paper abstracts in our dataset. </figcaption>

        <p>The asymmetry in HCI-AI influence is made even more obvious if we consider time slices of one conference with respect to the entire 20-year span of the other conference. If we select any one NeurIPS year in <a href="#lineChartAbstractButtons">Figure 5</a> and view the variation in cosine similarity with respect to 20 years of CHI, we will see a generally positive trend, meaning that CHI paper embeddings are becoming more similar to NeurIPS paper embeddings. On the other hand, if we select any CHI year and view the variation in cosine similarity with respect to 20 years of NeurIPS, we will see a generally flat trend. </p>
        <div id="lineChartAbstractButtons" class="selectorDiv">
          
          <div id="chiBtnGroup" class="btn-group">
            <button type="button" class="btn btn-primary dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              Select CHI Year:
            </button>
            <div id="chiDropdownYrs" class="dropdown-menu">
            </div>
          </div>
          <div id="NeuripsBtnGroup" class="btn-group">
            <button type="button" class="btn btn-primary dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              Select NeurIPS Year:
            </button>
            <div id="neuripsDropdownYrs" class="dropdown-menu">
            </div>
          </div>
        </div>
        <div id="lineChartAbstracts"></div>
        <figcaption>Figure 5: Line chart of cosine similarity among paper abstracts in our dataset. Select a year in one of the conference buttons above to anchor it and see variations in cosine similarity with respect to the entire 20-year span of the other conference.</figcaption>

        <p>After obtaining our abstract clusters, we labelled each cluster with a topic by prompting GPT-3 (text-davinci-003, temperature = 0.2) to summarize the cluster into a keyphrase. Due to token limitations in our free trial of the OpenAI API, we chose to only label clusters published in the last 5 years. Below is a table with the cluster labels. </p>
     
        <div>
          <form>
            <div id="chiYearSelector" class="form-group">
              <label for="formChiYear">Select CHI Year:</label>
              <select class="form-control" id="formChiYear" onchange="tfidfTopics()"></select>
            </div>
            <div id="neuripsYearSelector" class="form-group">
              <label for="formNeuripsYear">Select NeurIPS Year:</label>
              <select class="form-control" id="formNeuripsYear" onchange="tfidfTopics()"></select>
            </div>
          </form>

          <table id="topicsTable" class="table table-hover">
            <thead>
              <tr>
                <th scope="col">Conference</th>
                <th scope="col">Year</th>
                <th scope="col">Topic</th>
                <th scope="col">Number of Abstracts</th>
              </tr>
            </thead>
            <tbody>
            </tbody>
          </table>
        </div>

        

      </section>

      <section id="discussion">
        <h3>Discussion</h3>
        <h4>Limitations and Future Work</h4>
        <p>One limitation of our work is that we generated embeddings of each paper by encoding only the abstracts. While the abstract summarizes the essence of the paper, it lacks the details of the methodologies, related works, and results of the work. Future work may consider generating embeddings based on the full text of the paper. With a better representation of the papers in the semantic space, we would be able to compute similarity of papers more precisely. </p>

        <p>Another limitation is that when computing similarities, we only looked at the semantics of the papers (by encoding the abstracts). One additional relevant information that is not encoded in the text is the citation of the papers. Often, one would be able to tell if two papers are relevant by looking at their references. Including the citation information in the embedding would also help us find the intersecting papers of CHI and NeuRIPs papers. We considered using the SPECTER embeddings provided through the S2 API, but they were only available to a little under three-quarters of the papers in our dataset. Per the <a href="https://github.com/allenai/specter">SPECTER GitHub repository</a>, running SPECTER on our own machines will produce different results than those provided by the API due to differences in model versions. Future work may generate the SPECTER embeddings from scratch for standardization, and then use those embeddings for analysis.</p>

        <p>Lastly, the topics generated using GPT-3 lack a rigorous evaluation for their faithfulness. While GPT-3 has shown to be a powerful language model, we still would like to verify if the topics generated reflect the semantics of the clusters of abstracts. Our evaluation method is to sample a small set of abstracts, and verify if the topics make sense. However, with this method, we do not know if the topics are faithful at scale. Thus, one compelling avenue for future work is to build a human-in-the-loop system for topic generation where a user can confirm or correct a generated title, as well as ask the model to explain its decision-making through a natural language interface such as ChatGPT.</p>

      </section>

      <section id="conclusion">
        <h3>Conclusion</h3>
        <p>We collected and analyzed over 14,000 abstracts from papers published at CHI and NeurIPS over the past 20 years (2001 to 2021) to investigate the growing intersection between the fields of AI and HCI. We computed embeddings on paper abstracts using SciBERT and filtered papers with similar cross-domain embeddings: CHI abstracts with a high similarity score to NeurIPS abstracts and vice versa. We found an asymmetry in similarity scores, with CHI abstracts noticeably approaching similarity with NeurIPS abstracts but not the other way around. This points to the field of AI as being a larger influence on HCI than HCI is to AI. Furthermore, we clustered our filtered papers and used GPT-3 to generate topic labels, which we can then view in different combinations throughout the 20-year time period. We discuss guidelines on how to use those topics to derive future research questions. We hope that this analysis can inspire researchers to pursue new and exciting directions at the intersection of AI and HCI. </p>
      </section>

      <section id="materials">
        <h3>Materials</h3>
        <a href="">Download our data (.zip)</a><br>
        <a href="">View our analyis code (Google Colab)</a>
      </section>

      
    </div>

  </div>

  

  <div class="refs">
    <div class="col-lg-6 offset-lg-3" style="padding: 0">

      <!-- Citations -->
      <section id="bib-sec-001"> 
       <header> 
        <div class="title-info"> 
         <!-- <h3 class="page-brake-head"><span class="nav-open" role="button" onclick="openNav(this)" tabindex="0" title="article navigation" >References</span></h3>  -->
         <h3>References</h3>
        </div> 
       </header> 
       <ol class="bibUl"> 
        <li id="bib1" label="[1]" value="1">Grudin, Jonathan. "AI and HCI: Two fields divided by a common focus." Ai Magazine 30.4 (2009): 48-48. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li> 
        <li id="bib2" label="[2]" value="2">HCAI @ NeurIPS '22. "HCAI @ NeurIPS '22. Virtual Workshop on Human-Centered AI Workshop at NeurIPS" (2022). <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li> 
        <li id="bib3" label="[3]" value="3">Inkpen, Kori, et al. "Where is the human? Bridging the gap between AI and HCI." Extended abstracts of the 2019 chi conference on human factors in computing systems. 2019. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li> 
        <li id="bib4" label="[4]" value="4">Bansal, Gagan, et al. "Workshop on Trust and Reliance in AI-Human Teams (TRAIT)." CHI Conference on Human Factors in Computing Systems Extended Abstracts. 2022. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li> 
        <li id="bib5" label="[5]" value="5">Liu, Yong, et al. "CHI 1994-2013: Mapping two decades of intellectual progress through co-word analysis." Proceedings of the SIGCHI conference on human factors in computing systems. 2014. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li> 
        <li id="bib6" label="[6]" value="6">Microsoft Academic. "NeurIPS Conference Analytics." Microsoft Academic Blog. 2018. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li> 
        <li id="bib7" label="[7]" value="7">Devlin, Jacob, et al. "Bert: Pre-training of deep bidirectional transformers for language understanding." arXiv preprint arXiv:1810.04805 (2018). <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li> 
        <li id="bib8" label="[8]" value="8">Beltagy, Iz, Kyle Lo, and Arman Cohan. "SciBERT: A pretrained language model for scientific text." arXiv preprint arXiv:1903.10676 (2019). <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li>
        <li id="bib9" label="[9]" value="9">Cohan, Arman, et al. "Specter: Document-level representation learning using citation-informed transformers." arXiv preprint arXiv:2004.07180 (2020). <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li>
        <li id="bib10" label="[10]" value="10">Tshitoyan, Vahe et al. “Unsupervised word embeddings capture latent knowledge from materials science literature.” Nature 571 (2019): 95-98. <span class="link-das"> </span><select class="bib-ref-num" aria-label="Jump to citation for reference 1" style="display:inline-block;"><option>Navigate to</option><option value="#auto-bib11" aria-label="citation 1 reference 1">citation 1</option></select></li>

        
        
        
       </ol> 
   
     </section> 
  </div>
  



 
</body>



<script>
  $(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip({html: true});   
  });
  </script>
</html>